{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv file\n",
    "df_p1 = pd.read_csv('combined_dataset/Paslon1_full.csv')\n",
    "df_p2 = pd.read_csv('combined_dataset/Paslon2_full.csv')\n",
    "df_p3 = pd.read_csv('combined_dataset/Paslon3_full.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean and Modify Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mkmaa\\AppData\\Local\\Temp\\ipykernel_9660\\519926434.py:2: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'Anies' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_p1.loc[df_p1['keyword'] == 'Pres', 'target'] = 'Anies'\n",
      "C:\\Users\\mkmaa\\AppData\\Local\\Temp\\ipykernel_9660\\519926434.py:6: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'Prabowo' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_p2.loc[df_p2['keyword'] == 'Pres', 'target'] = 'Prabowo'\n",
      "C:\\Users\\mkmaa\\AppData\\Local\\Temp\\ipykernel_9660\\519926434.py:10: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'Ganjar' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_p3.loc[df_p3['keyword'] == 'Pres', 'target'] = 'Ganjar'\n"
     ]
    }
   ],
   "source": [
    "# create new label 'target' from column 'keyword'\n",
    "df_p1.loc[df_p1['keyword'] == 'Pres', 'target'] = 'Anies'\n",
    "df_p1.loc[df_p1['keyword'] == 'Wapres', 'target'] = 'Imin'\n",
    "df_p1.loc[df_p1['keyword'] == 'Akronim', 'target'] = 'AMin'\n",
    "\n",
    "df_p2.loc[df_p2['keyword'] == 'Pres', 'target'] = 'Prabowo'\n",
    "df_p2.loc[df_p2['keyword'] == 'Wapres', 'target'] = 'Gibran'\n",
    "df_p2.loc[df_p2['keyword'] == 'Akronim', 'target'] = 'Pragi'\n",
    "\n",
    "df_p3.loc[df_p3['keyword'] == 'Pres', 'target'] = 'Ganjar'\n",
    "df_p3.loc[df_p3['keyword'] == 'Wapres', 'target'] = 'Mahfud'\n",
    "df_p3.loc[df_p3['keyword'] == 'Akronim', 'target'] = 'GaMa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column paslon\n",
    "df_p1['paslon'] = 'P1'\n",
    "df_p2['paslon'] = 'P2'\n",
    "df_p3['paslon'] = 'P3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take date from created_at\n",
    "df_p1['created_at'] = pd.to_datetime(df_p1['created_at'])\n",
    "df_p1['date'] = df_p1['created_at'].dt.date\n",
    "df_p1['date'] = pd.to_datetime(df_p1['date'])\n",
    "\n",
    "df_p2['created_at'] = pd.to_datetime(df_p2['created_at'])\n",
    "df_p2['date'] = df_p2['created_at'].dt.date\n",
    "df_p2['date'] = pd.to_datetime(df_p2['date'])\n",
    "\n",
    "df_p3['created_at'] = pd.to_datetime(df_p3['created_at'])\n",
    "df_p3['date'] = df_p3['created_at'].dt.date\n",
    "df_p3['date'] = pd.to_datetime(df_p3['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paslon 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2023-12-05    266\n",
       "2023-12-06    413\n",
       "2023-12-07    365\n",
       "2023-12-08    457\n",
       "2023-12-09    472\n",
       "2023-12-10    397\n",
       "2023-12-11    443\n",
       "2023-12-12    777\n",
       "2023-12-13    779\n",
       "2023-12-14    610\n",
       "2023-12-15    388\n",
       "2023-12-16    642\n",
       "2023-12-17    398\n",
       "2023-12-18    499\n",
       "2023-12-19    524\n",
       "2023-12-20    489\n",
       "2023-12-21    535\n",
       "2023-12-22    754\n",
       "2023-12-23    941\n",
       "2023-12-24    455\n",
       "2023-12-25    486\n",
       "2023-12-26    368\n",
       "2023-12-27    426\n",
       "2023-12-28    535\n",
       "2023-12-29    542\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_p2['date'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keyword\n",
       "Pres       8272\n",
       "Wapres     4351\n",
       "Akronim     338\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_p2['keyword'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "Prabowo    8272\n",
       "Gibran     4351\n",
       "Pragi       338\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_p2['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paslon 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2023-12-05    266\n",
       "2023-12-06    413\n",
       "2023-12-07    365\n",
       "2023-12-08    457\n",
       "2023-12-09    472\n",
       "2023-12-10    397\n",
       "2023-12-11    443\n",
       "2023-12-12    777\n",
       "2023-12-13    779\n",
       "2023-12-14    610\n",
       "2023-12-15    388\n",
       "2023-12-16    642\n",
       "2023-12-17    398\n",
       "2023-12-18    499\n",
       "2023-12-19    524\n",
       "2023-12-20    489\n",
       "2023-12-21    535\n",
       "2023-12-22    754\n",
       "2023-12-23    941\n",
       "2023-12-24    455\n",
       "2023-12-25    486\n",
       "2023-12-26    368\n",
       "2023-12-27    426\n",
       "2023-12-28    535\n",
       "2023-12-29    542\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_p2['date'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keyword\n",
       "Pres       8272\n",
       "Wapres     4351\n",
       "Akronim     338\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_p2['keyword'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "Prabowo    8272\n",
       "Gibran     4351\n",
       "Pragi       338\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_p2['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paslon 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2023-12-05    240\n",
       "2023-12-06    269\n",
       "2023-12-07    347\n",
       "2023-12-08    395\n",
       "2023-12-09    625\n",
       "2023-12-10    262\n",
       "2023-12-11    229\n",
       "2023-12-12    399\n",
       "2023-12-13    245\n",
       "2023-12-14    333\n",
       "2023-12-15    431\n",
       "2023-12-16    195\n",
       "2023-12-17    253\n",
       "2023-12-18    263\n",
       "2023-12-19    271\n",
       "2023-12-20    262\n",
       "2023-12-21    292\n",
       "2023-12-22    439\n",
       "2023-12-23    255\n",
       "2023-12-24    302\n",
       "2023-12-25    274\n",
       "2023-12-26    266\n",
       "2023-12-27    350\n",
       "2023-12-28    314\n",
       "2023-12-29    289\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_p3['date'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keyword\n",
       "Pres       3678\n",
       "Akronim    2529\n",
       "Wapres     1593\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_p3['keyword'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "Ganjar    3678\n",
       "GaMa      2529\n",
       "Mahfud    1593\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_p3['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 34341 entries, 0 to 7799\n",
      "Data columns (total 18 columns):\n",
      " #   Column               Non-Null Count  Dtype                    \n",
      "---  ------               --------------  -----                    \n",
      " 0   created_at           34341 non-null  datetime64[ns, UTC+07:00]\n",
      " 1   id_str               34341 non-null  int64                    \n",
      " 2   full_text            34341 non-null  object                   \n",
      " 3   quote_count          34341 non-null  int64                    \n",
      " 4   reply_count          34341 non-null  int64                    \n",
      " 5   retweet_count        34341 non-null  int64                    \n",
      " 6   favorite_count       34341 non-null  object                   \n",
      " 7   lang                 34341 non-null  object                   \n",
      " 8   user_id_str          34341 non-null  int64                    \n",
      " 9   conversation_id_str  34341 non-null  object                   \n",
      " 10  username             34341 non-null  object                   \n",
      " 11  tweet_url            34335 non-null  object                   \n",
      " 12  image_url            19956 non-null  object                   \n",
      " 13  location             19319 non-null  object                   \n",
      " 14  keyword              34341 non-null  object                   \n",
      " 15  target               34341 non-null  object                   \n",
      " 16  paslon               34341 non-null  object                   \n",
      " 17  date                 34341 non-null  datetime64[ns]           \n",
      "dtypes: datetime64[ns, UTC+07:00](1), datetime64[ns](1), int64(5), object(11)\n",
      "memory usage: 5.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# combine data\n",
    "df = pd.concat([df_p1, df_p2, df_p3])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean combined Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Data by Text:  1459\n",
      "Total Data after Drop:  32882\n"
     ]
    }
   ],
   "source": [
    "# count duplicate data based on full_text\n",
    "print(\"Duplicate Data by Text: \", df['full_text'].duplicated().sum())\n",
    "\n",
    "# drop duplicate data based on full_text\n",
    "df = df.drop_duplicates(subset=['full_text'])\n",
    "print(\"Total Data after Drop: \", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "6\n",
      "Total Data after Drop:  32860\n"
     ]
    }
   ],
   "source": [
    "# check data with \"dood\", \"Dood\" in full_text and username\n",
    "print(len(df[df['full_text'].str.contains(\"dood|Dood\")]))\n",
    "print(len(df[df['username'].str.contains(\"dood|Dood\")]))\n",
    "\n",
    "# drop data with \"dood\", \"Dood\" in full_text and username\n",
    "df = df[~df['full_text'].str.contains(\"dood|Dood\")]\n",
    "df = df[~df['username'].str.contains(\"dood|Dood\")]\n",
    "print(\"Total Data after Drop: \", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data 'full_text' language\n",
    "def detect_lang(text):\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "df['lang'] = df['full_text'].apply(detect_lang)\n",
    "df['lang'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Data after Drop:  27241\n"
     ]
    }
   ],
   "source": [
    "# drop data with 'lang' not 'id'\n",
    "df = df[df['lang'] == 'id']\n",
    "print(\"Total Data after Drop: \", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "Prabowo    7221\n",
       "Anies      5387\n",
       "Gibran     3983\n",
       "Imin       3422\n",
       "Ganjar     3150\n",
       "GaMa       2247\n",
       "Mahfud     1245\n",
       "Pragi       313\n",
       "AMin        273\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keyword\n",
       "Pres       15758\n",
       "Wapres      8650\n",
       "Akronim     2833\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['keyword'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "paslon\n",
       "P2    11517\n",
       "P1     9082\n",
       "P3     6642\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['paslon'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "df.to_csv('combined_dataset/Full.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 16000 entries, 10000 to 11784\n",
      "Data columns (total 18 columns):\n",
      " #   Column               Non-Null Count  Dtype                    \n",
      "---  ------               --------------  -----                    \n",
      " 0   created_at           16000 non-null  datetime64[ns, UTC+07:00]\n",
      " 1   id_str               16000 non-null  int64                    \n",
      " 2   full_text            16000 non-null  object                   \n",
      " 3   quote_count          16000 non-null  int64                    \n",
      " 4   reply_count          16000 non-null  int64                    \n",
      " 5   retweet_count        16000 non-null  int64                    \n",
      " 6   favorite_count       16000 non-null  object                   \n",
      " 7   lang                 16000 non-null  object                   \n",
      " 8   user_id_str          16000 non-null  int64                    \n",
      " 9   conversation_id_str  16000 non-null  object                   \n",
      " 10  username             16000 non-null  object                   \n",
      " 11  tweet_url            15995 non-null  object                   \n",
      " 12  image_url            9438 non-null   object                   \n",
      " 13  location             8960 non-null   object                   \n",
      " 14  keyword              16000 non-null  object                   \n",
      " 15  target               16000 non-null  object                   \n",
      " 16  paslon               16000 non-null  object                   \n",
      " 17  date                 16000 non-null  datetime64[ns]           \n",
      "dtypes: datetime64[ns, UTC+07:00](1), datetime64[ns](1), int64(5), object(11)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# take 15000 sample data \n",
    "df_sample = df.sample(n=16000, random_state=1)\n",
    "df_sample.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2023-12-05    500\n",
       "2023-12-06    533\n",
       "2023-12-07    565\n",
       "2023-12-08    612\n",
       "2023-12-09    792\n",
       "2023-12-10    572\n",
       "2023-12-11    516\n",
       "2023-12-12    870\n",
       "2023-12-13    744\n",
       "2023-12-14    815\n",
       "2023-12-15    669\n",
       "2023-12-16    654\n",
       "2023-12-17    476\n",
       "2023-12-18    650\n",
       "2023-12-19    640\n",
       "2023-12-20    562\n",
       "2023-12-21    633\n",
       "2023-12-22    762\n",
       "2023-12-23    891\n",
       "2023-12-24    641\n",
       "2023-12-25    503\n",
       "2023-12-26    431\n",
       "2023-12-27    595\n",
       "2023-12-28    735\n",
       "2023-12-29    639\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample['date'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "paslon\n",
       "P2    6772\n",
       "P1    5360\n",
       "P3    3868\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample['paslon'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keyword\n",
       "Pres       9263\n",
       "Wapres     5069\n",
       "Akronim    1668\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample['keyword'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "Prabowo    4248\n",
       "Anies      3186\n",
       "Gibran     2348\n",
       "Imin       2000\n",
       "Ganjar     1829\n",
       "GaMa       1318\n",
       "Mahfud      721\n",
       "Pragi       176\n",
       "AMin        174\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "df_sample.to_csv('combined_dataset/Sample.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into dataset with 2000 data each\n",
    "df_sample1 = df_sample.iloc[:2000]\n",
    "df_sample2 = df_sample.iloc[2000:4000]\n",
    "df_sample3 = df_sample.iloc[4000:6000]\n",
    "df_sample4 = df_sample.iloc[6000:8000]\n",
    "df_sample5 = df_sample.iloc[8000:10000]\n",
    "df_sample6 = df_sample.iloc[10000:12500]\n",
    "df_sample7 = df_sample.iloc[12500:15000]\n",
    "df_sample8 = df_sample.iloc[15000:]\n",
    "\n",
    "# save to csv\n",
    "df_sample1.to_csv('combined_dataset/Sample1.csv', index=False)\n",
    "df_sample2.to_csv('combined_dataset/Sample2.csv', index=False)\n",
    "df_sample3.to_csv('combined_dataset/Sample3.csv', index=False)\n",
    "df_sample4.to_csv('combined_dataset/Sample4.csv', index=False)\n",
    "df_sample5.to_csv('combined_dataset/Sample5.csv', index=False)\n",
    "df_sample6.to_csv('combined_dataset/Sample6.csv', index=False)\n",
    "df_sample7.to_csv('combined_dataset/Sample7.csv', index=False)\n",
    "df_sample8.to_csv('combined_dataset/Sample8.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean unrelated data (tambahan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataset sample\n",
    "df_sample_fix = pd.read_csv('combined_dataset/Sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 0 entries\n",
      "Data columns (total 19 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   created_at           0 non-null      object\n",
      " 1   id_str               0 non-null      int64 \n",
      " 2   full_text            0 non-null      object\n",
      " 3   quote_count          0 non-null      int64 \n",
      " 4   reply_count          0 non-null      int64 \n",
      " 5   retweet_count        0 non-null      int64 \n",
      " 6   favorite_count       0 non-null      object\n",
      " 7   lang                 0 non-null      object\n",
      " 8   user_id_str          0 non-null      int64 \n",
      " 9   conversation_id_str  0 non-null      object\n",
      " 10  username             0 non-null      object\n",
      " 11  tweet_url            0 non-null      object\n",
      " 12  image_url            0 non-null      object\n",
      " 13  location             0 non-null      object\n",
      " 14  keyword              0 non-null      object\n",
      " 15  target               0 non-null      object\n",
      " 16  paslon               0 non-null      object\n",
      " 17  date                 0 non-null      object\n",
      " 18  lowercase            0 non-null      object\n",
      "dtypes: int64(5), object(14)\n",
      "memory usage: 0.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "# check data that having no 'Anies', 'Muhaimin', 'Amin', 'Prabowo', 'Gibran', 'Pragi', 'Ganjar', 'Mahfud' and 'Gama' in full_text\n",
    "df_sample_fix[\"lowercase\"] = df_sample_fix[\"full_text\"].str.lower()\n",
    "print(len(df_sample_fix[~df_sample_fix['lowercase'].str.contains(\"anies|muhaimin|amin|prabowo|gibran|pragi|ganjar|mahfud|gama\")]))\n",
    "\n",
    "df_dump = df_sample_fix[~df_sample_fix['lowercase'].str.contains(\"anies|muhaimin|amin|prabowo|gibran|pragi|ganjar|mahfud|gama\")]\n",
    "df_dump.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to csv\n",
    "df_dump.to_csv('combined_dataset/dump.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Data after Drop:  15487\n"
     ]
    }
   ],
   "source": [
    "# drop data that having no 'Anies', 'Muhaimin', 'Amin', 'Prabowo', 'Gibran', 'Pragi', 'Ganjar', 'Mahfud' and 'Gama' in full_text\n",
    "df_sample_fix = df_sample_fix[df_sample_fix['lowercase'].str.contains(\"anies|muhaimin|amin|prabowo|gibran|pragi|ganjar|mahfud|gama\")]\n",
    "\n",
    "# drop column lowercase\n",
    "df_sample_fix = df_sample_fix.drop(columns=['lowercase'])\n",
    "\n",
    "print(\"Total Data after Drop: \", len(df_sample_fix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "Prabowo    4182\n",
       "Anies      3107\n",
       "Gibran     2251\n",
       "Imin       1887\n",
       "Ganjar     1794\n",
       "GaMa       1296\n",
       "Mahfud      636\n",
       "Pragi       173\n",
       "AMin        161\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample_fix['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keyword\n",
       "Pres       9083\n",
       "Wapres     4774\n",
       "Akronim    1630\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample_fix['keyword'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "paslon\n",
       "P2    6606\n",
       "P1    5155\n",
       "P3    3726\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample_fix['paslon'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2023-12-05    478\n",
       "2023-12-06    516\n",
       "2023-12-07    543\n",
       "2023-12-08    595\n",
       "2023-12-09    759\n",
       "2023-12-10    550\n",
       "2023-12-11    498\n",
       "2023-12-12    856\n",
       "2023-12-13    732\n",
       "2023-12-14    776\n",
       "2023-12-15    653\n",
       "2023-12-16    634\n",
       "2023-12-17    460\n",
       "2023-12-18    628\n",
       "2023-12-19    623\n",
       "2023-12-20    542\n",
       "2023-12-21    617\n",
       "2023-12-22    743\n",
       "2023-12-23    861\n",
       "2023-12-24    612\n",
       "2023-12-25    485\n",
       "2023-12-26    418\n",
       "2023-12-27    572\n",
       "2023-12-28    709\n",
       "2023-12-29    627\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample_fix['date'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "df_sample_fix.to_csv('combined_dataset/Sample V2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv\n",
    "df_full = pd.read_csv('combined_dataset/Full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "885\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 885 entries, 0 to 27105\n",
      "Data columns (total 19 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   created_at           885 non-null    object\n",
      " 1   id_str               885 non-null    int64 \n",
      " 2   full_text            885 non-null    object\n",
      " 3   quote_count          885 non-null    int64 \n",
      " 4   reply_count          885 non-null    int64 \n",
      " 5   retweet_count        885 non-null    int64 \n",
      " 6   favorite_count       885 non-null    object\n",
      " 7   lang                 885 non-null    object\n",
      " 8   user_id_str          885 non-null    int64 \n",
      " 9   conversation_id_str  885 non-null    object\n",
      " 10  username             885 non-null    object\n",
      " 11  tweet_url            885 non-null    object\n",
      " 12  image_url            341 non-null    object\n",
      " 13  location             608 non-null    object\n",
      " 14  keyword              885 non-null    object\n",
      " 15  target               885 non-null    object\n",
      " 16  paslon               885 non-null    object\n",
      " 17  date                 885 non-null    object\n",
      " 18  lowercase            885 non-null    object\n",
      "dtypes: int64(5), object(14)\n",
      "memory usage: 138.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# check data that having no 'Anies', 'Muhaimin', 'Amin', 'Prabowo', 'Gibran', 'Pragi', 'Ganjar', 'Mahfud' and 'Gama' in full_text\n",
    "df_full[\"lowercase\"] = df_full[\"full_text\"].str.lower()\n",
    "print(len(df_full[~df_full['lowercase'].str.contains(\"anies|muhaimin|amin|prabowo|gibran|pragi|ganjar|mahfud|gama\")]))\n",
    "\n",
    "df_dump = df_full[~df_full['lowercase'].str.contains(\"anies|muhaimin|amin|prabowo|gibran|pragi|ganjar|mahfud|gama\")]\n",
    "df_dump.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to csv\n",
    "df_dump.to_csv('combined_dataset/dump_full.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Data after Drop:  26356\n"
     ]
    }
   ],
   "source": [
    "# drop data that having no 'Anies', 'Muhaimin', 'Amin', 'Prabowo', 'Gibran', 'Pragi', 'Ganjar', 'Mahfud' and 'Gama' in full_text\n",
    "df_full = df_full[df_full['lowercase'].str.contains(\"anies|muhaimin|amin|prabowo|gibran|pragi|ganjar|mahfud|gama\")]\n",
    "\n",
    "# drop column lowercase\n",
    "df_full = df_full.drop(columns=['lowercase'])\n",
    "\n",
    "print(\"Total Data after Drop: \", len(df_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "df_full.to_csv('combined_dataset/Full V2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu-python-3-10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
