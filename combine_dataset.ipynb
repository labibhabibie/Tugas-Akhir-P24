{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     created_at               id_str  \\\n",
      "0     2023-12-05 00:44:13+07:00  1731731142414639465   \n",
      "1     2023-12-05 02:01:30+07:00  1731750593943765458   \n",
      "2     2023-12-05 02:32:31+07:00  1731758398738473157   \n",
      "3     2023-12-05 03:31:16+07:00  1731773183508852944   \n",
      "4     2023-12-05 04:33:33+07:00  1731788857472123177   \n",
      "...                         ...                  ...   \n",
      "7815  2023-12-29 23:50:57+07:00  1740777435598143956   \n",
      "7816  2023-12-29 23:50:58+07:00  1740777440660828351   \n",
      "7817  2023-12-29 23:51:10+07:00  1740777490128441779   \n",
      "7818  2023-12-29 23:54:32+07:00  1740778337751224703   \n",
      "7819  2023-12-29 23:58:08+07:00  1740779243892818396   \n",
      "\n",
      "                                              full_text  quote_count  \\\n",
      "0     baca Majalah Tempo terbaru ini bikin resah. di...            6   \n",
      "1     Allah sa mu gama da duniya lafiya  Allah bamu ...            3   \n",
      "2     Bagaimana pun  posisi saya jelas mendukung Gan...            6   \n",
      "3     @officialinews_ Ganjar Mahfud M3nang Indonesia...            0   \n",
      "4     Percepat langkah  ..kuatkan dukungan pd Gama u...            4   \n",
      "...                                                 ...          ...   \n",
      "7815  ðŸ‘‡ðŸ‘‡ðŸ‘‡ðŸ‘‡ðŸ‘‡ðŸ‘‡ðŸ‘‡   # #MahfudLebihBaik3 #GanjarMahfud202...            0   \n",
      "7816  ðŸ‘‡ðŸ‘‡ðŸ‘‡ðŸ‘‡ðŸ‘‡ðŸ‘‡ðŸ‘‡   # #MahfudLebihBaik3 #GanjarMahfud202...            0   \n",
      "7817  ðŸ‘‡ðŸ‘‡ðŸ‘‡ðŸ‘‡ðŸ‘‡ðŸ‘‡ðŸ‘‡   # #MahfudLebihBaik3 #GanjarMahfud202...            0   \n",
      "7818  Pastikan kalian hadir di Pesta Rakyat Ganjar-M...            0   \n",
      "7819  Janji Babat Korupsi  Mahfud Md: Aparat Tak Bol...            2   \n",
      "\n",
      "      reply_count  retweet_count  favorite_count lang          user_id_str  \\\n",
      "0               3             86             207   in  1067463821252472832   \n",
      "1               0             24              19   in           1207085623   \n",
      "2              77             53             392   in             70828230   \n",
      "3               0              0               0   in  1708707192239738880   \n",
      "4               9            145             532   in  1264902602342334470   \n",
      "...           ...            ...             ...  ...                  ...   \n",
      "7815            0              0               0   in  1645491622669426700   \n",
      "7816            0              0               0   in             99862944   \n",
      "7817            0              0               0   in           2226482431   \n",
      "7818            0              8              46   in  1230994530083565568   \n",
      "7819          108             78             115   in             18129942   \n",
      "\n",
      "      conversation_id_str        username  \\\n",
      "0     1731731142414639465         107aWvS   \n",
      "1     1731750593943765458        HafsiSi_   \n",
      "2     1731758398738473157        dawiguna   \n",
      "3     1731562729293431073         Abrhmz_   \n",
      "4     1731788857472123177     Flamboyan59   \n",
      "...                   ...             ...   \n",
      "7815  1740777435598143956        _evaaa02   \n",
      "7816  1740777440660828351    0x_LoriMarie   \n",
      "7817  1740777490128441779  AbhinavBusawon   \n",
      "7818  1740778337751224703   sahabatganjar   \n",
      "7819  1740779243892818396      tempodotco   \n",
      "\n",
      "                                              tweet_url  \\\n",
      "0     https://twitter.com/107aWvS/status/17317311424...   \n",
      "1     https://twitter.com/HafsiSi_/status/1731750593...   \n",
      "2     https://twitter.com/dawiguna/status/1731758398...   \n",
      "3     https://twitter.com/Abrhmz_/status/17317731835...   \n",
      "4     https://twitter.com/Flamboyan59/status/1731788...   \n",
      "...                                                 ...   \n",
      "7815  https://twitter.com/_evaaa02/status/1740777435...   \n",
      "7816  https://twitter.com/0x_LoriMarie/status/174077...   \n",
      "7817  https://twitter.com/AbhinavBusawon/status/1740...   \n",
      "7818  https://twitter.com/sahabatganjar/status/17407...   \n",
      "7819  https://twitter.com/tempodotco/status/17407792...   \n",
      "\n",
      "                                              image_url  \\\n",
      "0                                                   NaN   \n",
      "1                                                   NaN   \n",
      "2       https://pbs.twimg.com/media/GAhxFIdaYAA6vON.jpg   \n",
      "3                                                   NaN   \n",
      "4     https://pbs.twimg.com/ext_tw_video_thumb/17317...   \n",
      "...                                                 ...   \n",
      "7815                                                NaN   \n",
      "7816                                                NaN   \n",
      "7817                                                NaN   \n",
      "7818  https://pbs.twimg.com/ext_tw_video_thumb/17407...   \n",
      "7819                                                NaN   \n",
      "\n",
      "                            location  keyword  \n",
      "0                      Mount Olympus  Akronim  \n",
      "1                            Nigeria   Wapres  \n",
      "2     Bandung, Jawa Barat, Indonesia  Akronim  \n",
      "3                                NaN  Akronim  \n",
      "4       Indonesia NO DM â›”. PORN BLOK   Wapres  \n",
      "...                              ...      ...  \n",
      "7815                             NaN  Akronim  \n",
      "7816                 Kenora, Ontario  Akronim  \n",
      "7817                             NaN  Akronim  \n",
      "7818                             NaN     Pres  \n",
      "7819                       Indonesia  Akronim  \n",
      "\n",
      "[7820 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "# Path to the directory containing your datasets\n",
    "data_directory = \"cleaned_dataset/paslon3/\"\n",
    "\n",
    "# List to store individual DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Loop through files in the directory\n",
    "for filename in os.listdir(data_directory):\n",
    "    if filename.endswith(\".csv\"):  # Assuming your datasets are in CSV format\n",
    "        file_path = os.path.join(data_directory, filename)\n",
    "        \n",
    "        # Read each CSV file into a DataFrame and append it to the list\n",
    "        df = pd.read_csv(file_path)\n",
    "        dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames in the list into one big DataFrame\n",
    "big_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Display the combined DataFrame\n",
    "print(big_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.count of                      created_at               id_str  \\\n",
       "0     2023-12-05 00:44:13+07:00  1731731142414639465   \n",
       "1     2023-12-05 02:01:30+07:00  1731750593943765458   \n",
       "2     2023-12-05 02:32:31+07:00  1731758398738473157   \n",
       "3     2023-12-05 03:31:16+07:00  1731773183508852944   \n",
       "4     2023-12-05 04:33:33+07:00  1731788857472123177   \n",
       "...                         ...                  ...   \n",
       "7815  2023-12-29 23:50:57+07:00  1740777435598143956   \n",
       "7816  2023-12-29 23:50:58+07:00  1740777440660828351   \n",
       "7817  2023-12-29 23:51:10+07:00  1740777490128441779   \n",
       "7818  2023-12-29 23:54:32+07:00  1740778337751224703   \n",
       "7819  2023-12-29 23:58:08+07:00  1740779243892818396   \n",
       "\n",
       "                                              full_text  quote_count  \\\n",
       "0     baca Majalah Tempo terbaru ini bikin resah. di...            6   \n",
       "1     Allah sa mu gama da duniya lafiya  Allah bamu ...            3   \n",
       "2     Bagaimana pun  posisi saya jelas mendukung Gan...            6   \n",
       "3     @officialinews_ Ganjar Mahfud M3nang Indonesia...            0   \n",
       "4     Percepat langkah  ..kuatkan dukungan pd Gama u...            4   \n",
       "...                                                 ...          ...   \n",
       "7815  ðŸ‘‡ðŸ‘‡ðŸ‘‡ðŸ‘‡ðŸ‘‡ðŸ‘‡ðŸ‘‡   # #MahfudLebihBaik3 #GanjarMahfud202...            0   \n",
       "7816  ðŸ‘‡ðŸ‘‡ðŸ‘‡ðŸ‘‡ðŸ‘‡ðŸ‘‡ðŸ‘‡   # #MahfudLebihBaik3 #GanjarMahfud202...            0   \n",
       "7817  ðŸ‘‡ðŸ‘‡ðŸ‘‡ðŸ‘‡ðŸ‘‡ðŸ‘‡ðŸ‘‡   # #MahfudLebihBaik3 #GanjarMahfud202...            0   \n",
       "7818  Pastikan kalian hadir di Pesta Rakyat Ganjar-M...            0   \n",
       "7819  Janji Babat Korupsi  Mahfud Md: Aparat Tak Bol...            2   \n",
       "\n",
       "      reply_count  retweet_count  favorite_count lang          user_id_str  \\\n",
       "0               3             86             207   in  1067463821252472832   \n",
       "1               0             24              19   in           1207085623   \n",
       "2              77             53             392   in             70828230   \n",
       "3               0              0               0   in  1708707192239738880   \n",
       "4               9            145             532   in  1264902602342334470   \n",
       "...           ...            ...             ...  ...                  ...   \n",
       "7815            0              0               0   in  1645491622669426700   \n",
       "7816            0              0               0   in             99862944   \n",
       "7817            0              0               0   in           2226482431   \n",
       "7818            0              8              46   in  1230994530083565568   \n",
       "7819          108             78             115   in             18129942   \n",
       "\n",
       "      conversation_id_str        username  \\\n",
       "0     1731731142414639465         107aWvS   \n",
       "1     1731750593943765458        HafsiSi_   \n",
       "2     1731758398738473157        dawiguna   \n",
       "3     1731562729293431073         Abrhmz_   \n",
       "4     1731788857472123177     Flamboyan59   \n",
       "...                   ...             ...   \n",
       "7815  1740777435598143956        _evaaa02   \n",
       "7816  1740777440660828351    0x_LoriMarie   \n",
       "7817  1740777490128441779  AbhinavBusawon   \n",
       "7818  1740778337751224703   sahabatganjar   \n",
       "7819  1740779243892818396      tempodotco   \n",
       "\n",
       "                                              tweet_url  \\\n",
       "0     https://twitter.com/107aWvS/status/17317311424...   \n",
       "1     https://twitter.com/HafsiSi_/status/1731750593...   \n",
       "2     https://twitter.com/dawiguna/status/1731758398...   \n",
       "3     https://twitter.com/Abrhmz_/status/17317731835...   \n",
       "4     https://twitter.com/Flamboyan59/status/1731788...   \n",
       "...                                                 ...   \n",
       "7815  https://twitter.com/_evaaa02/status/1740777435...   \n",
       "7816  https://twitter.com/0x_LoriMarie/status/174077...   \n",
       "7817  https://twitter.com/AbhinavBusawon/status/1740...   \n",
       "7818  https://twitter.com/sahabatganjar/status/17407...   \n",
       "7819  https://twitter.com/tempodotco/status/17407792...   \n",
       "\n",
       "                                              image_url  \\\n",
       "0                                                   NaN   \n",
       "1                                                   NaN   \n",
       "2       https://pbs.twimg.com/media/GAhxFIdaYAA6vON.jpg   \n",
       "3                                                   NaN   \n",
       "4     https://pbs.twimg.com/ext_tw_video_thumb/17317...   \n",
       "...                                                 ...   \n",
       "7815                                                NaN   \n",
       "7816                                                NaN   \n",
       "7817                                                NaN   \n",
       "7818  https://pbs.twimg.com/ext_tw_video_thumb/17407...   \n",
       "7819                                                NaN   \n",
       "\n",
       "                            location  keyword  \n",
       "0                      Mount Olympus  Akronim  \n",
       "1                            Nigeria   Wapres  \n",
       "2     Bandung, Jawa Barat, Indonesia  Akronim  \n",
       "3                                NaN  Akronim  \n",
       "4       Indonesia NO DM â›”. PORN BLOK   Wapres  \n",
       "...                              ...      ...  \n",
       "7815                             NaN  Akronim  \n",
       "7816                 Kenora, Ontario  Akronim  \n",
       "7817                             NaN  Akronim  \n",
       "7818                             NaN     Pres  \n",
       "7819                       Indonesia  Akronim  \n",
       "\n",
       "[7820 rows x 15 columns]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Data by Text:  20\n",
      "Total Data after Drop:  7800\n"
     ]
    }
   ],
   "source": [
    "# count duplicate data based on full_text\n",
    "print(\"Duplicate Data by Text: \", big_df['full_text'].duplicated().sum())\n",
    "\n",
    "# drop duplicate data based on full_text\n",
    "big_df = big_df.drop_duplicates(subset=['full_text'])\n",
    "print(\"Total Data after Drop: \", len(big_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to csv\n",
    "big_df.to_csv('combined_dataset/Paslon3_full.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7500 entries, 2116 to 7137\n",
      "Data columns (total 15 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   created_at           7500 non-null   object\n",
      " 1   id_str               7500 non-null   int64 \n",
      " 2   full_text            7500 non-null   object\n",
      " 3   quote_count          7500 non-null   int64 \n",
      " 4   reply_count          7500 non-null   int64 \n",
      " 5   retweet_count        7500 non-null   int64 \n",
      " 6   favorite_count       7500 non-null   int64 \n",
      " 7   lang                 7500 non-null   object\n",
      " 8   user_id_str          7500 non-null   int64 \n",
      " 9   conversation_id_str  7500 non-null   int64 \n",
      " 10  username             7500 non-null   object\n",
      " 11  tweet_url            7500 non-null   object\n",
      " 12  image_url            4688 non-null   object\n",
      " 13  location             4417 non-null   object\n",
      " 14  keyword              7500 non-null   object\n",
      "dtypes: int64(7), object(8)\n",
      "memory usage: 937.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# take random sample data\n",
    "df_sample = big_df.sample(n=7500, random_state=42)\n",
    "df_sample.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7500 entries, 2116 to 7137\n",
      "Data columns (total 16 columns):\n",
      " #   Column               Non-Null Count  Dtype                                \n",
      "---  ------               --------------  -----                                \n",
      " 0   created_at           7500 non-null   datetime64[ns, pytz.FixedOffset(420)]\n",
      " 1   id_str               7500 non-null   int64                                \n",
      " 2   full_text            7500 non-null   object                               \n",
      " 3   quote_count          7500 non-null   int64                                \n",
      " 4   reply_count          7500 non-null   int64                                \n",
      " 5   retweet_count        7500 non-null   int64                                \n",
      " 6   favorite_count       7500 non-null   int64                                \n",
      " 7   lang                 7500 non-null   object                               \n",
      " 8   user_id_str          7500 non-null   int64                                \n",
      " 9   conversation_id_str  7500 non-null   int64                                \n",
      " 10  username             7500 non-null   object                               \n",
      " 11  tweet_url            7500 non-null   object                               \n",
      " 12  image_url            4688 non-null   object                               \n",
      " 13  location             4417 non-null   object                               \n",
      " 14  keyword              7500 non-null   object                               \n",
      " 15  date                 7500 non-null   datetime64[ns]                       \n",
      "dtypes: datetime64[ns, pytz.FixedOffset(420)](1), datetime64[ns](1), int64(7), object(7)\n",
      "memory usage: 996.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# take date from created_at\n",
    "df_sample['created_at'] = pd.to_datetime(df_sample['created_at'])\n",
    "df_sample['date'] = df_sample['created_at'].dt.date\n",
    "df_sample['date'] = pd.to_datetime(df_sample['date'])\n",
    "df_sample.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to csv\n",
    "df_sample.to_csv('combined_dataset/Paslon3_sample.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.18 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e26da9777431fcd98778416b583e2cb3f0c4f5515b7897587b203af2bddddd45"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
